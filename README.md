<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=220&section=header&text=Arman%20Faisal&fontSize=80&fontAlignY=35&animation=twinkling&fontColor=fff&desc=AI%20Systems%20Engineer%20%7C%20Full-Stack%20Developer&descAlignY=55&descSize=22" width="100%"/>

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/armanfaisal)
[![Portfolio](https://img.shields.io/badge/Portfolio-FF5722?style=for-the-badge&logo=google-chrome&logoColor=white)](https://armanfaisal.dev)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:armanfaisal0007@gmail.com)

### ü§ñ Bridging the Gap Between Research and Production
Building scalable, optimized AI systems with a focus on NLP and MLOps.

</div>

---

### üë®‚Äçüíª Professional Profile

I am a final-year **Artificial Intelligence student at FAST-NUCES**, specializing in transforming complex machine learning models into high-performance, production-ready applications. My work focuses on **efficiency**‚Äîwhether it's reducing token fertility for low-resource languages or slashing inference latency in serverless environments.

* **Current Focus:** Urdu-centric LLM optimization and Cloud-Native AI architecture.
* **Core Philosophy:** "A model is only as good as its deployment." 
* **Active Exploration:** LLM Observability, RAG Pipelines, and Quantization techniques.

---

### üõ†Ô∏è The Tech Ecosystem

| **Area** | **Technologies & Frameworks** |
| :--- | :--- |
| **Artificial Intelligence** | `PyTorch` `TensorFlow` `HuggingFace` `OpenCV` `Scikit-Learn` |
| **MLOps & Cloud** | `AWS (Lambda/S3)` `Docker` `ONNX` `GitHub Actions` `Linux` |
| **Backend & APIs** | `FastAPI` `Django` `Supabase` `Node.js` `.NET` |
| **Frontend** | `React` `Tailwind CSS v4` `JavaScript (ES6+)` |
| **Languages** | `Python` `C++` `SQL` `Java` |

---

### üöÄ Engineering Highlights

#### üî§ [Urdu Two-Stage BPE Tokenizer](https://github.com/ArmanFaisal)
*NLP & Script Engineering*
* **The Problem:** Standard LLM tokenizers over-segment Urdu Nastalƒ´q, leading to high "token fertility" and cost.
* **The Solution:** Developed a custom script-aware BPE strategy with Unicode normalization.
* **Impact:** **7.08% reduction in token fertility**, enabling faster and more cost-effective Urdu NLP.

#### ‚ö° [Serverless MNIST Recognizer](https://github.com/ArmanFaisal)
*Cloud-Native ML / MLOps*
* **The Problem:** High cold-start latency and large image sizes in serverless ML deployments.
* **The Solution:** Converted models to **ONNX** format and utilized multi-stage **Docker** builds on AWS Lambda.
* **Impact:** **90% latency reduction** and **70% reduction** in container image size.

#### üêæ [AnimalCLEF25 Re-ID System](https://github.com/ArmanFaisal)
*Computer Vision & Metric Learning*
* **The Problem:** Identifying individual animals in the wild with fine-grained visual differences.
* **The Solution:** Implemented a deep metric learning pipeline using **Triplet Loss** and high-dimensional feature embedding.
* **Tech:** PyTorch, OpenCV, ResNet/ViT backbones.

---

### üìä GitHub Insights

<div align="center">
  <img height="180em" src="https://github-readme-stats.vercel.app/api?username=ArmanFaisal&show_icons=true&theme=tokyonight&include_all_commits=true&count_private=true&border_radius=10&hide_border=true&bg_color=0D1117&title_color=6C63FF&icon_color=6C63FF&text_color=C9D1D9"/>
  <img height="180em" src="https://github-readme-stats.vercel.app/api/top-langs/?username=ArmanFaisal&layout=compact&theme=tokyonight&border_radius=10&hide_border=true&bg_color=0D1117&title_color=6C63FF&text_color=C9D1D9&langs_count=8"/>
</div>

---

### üèÜ Engineering Mindset

```python
class ArmanFaisal:
    def __init__(self):
        self.role = "AI Systems Engineer"
        self.location = "Karachi, Pakistan"
        self.base_stack = ["Python", "PyTorch", "AWS", "Docker"]

    def solve_problem(self, problem):
        # 1. Analyze script/data bottlenecks
        # 2. Architect for scale (Serverless/Microservices)
        # 3. Optimize (Quantization/Efficient Tokenization)
        return "Production-Ready Solution"

    def get_status(self):
        return "Open for AI/ML Research & High-Scale Project Collaboration"
